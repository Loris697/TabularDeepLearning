{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\loris\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2023.10.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (0.11.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (1.26.4)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: torch<4.0,>=1.13.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (2.2.2)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (1.3.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (4.9.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning) (2.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\loris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\loris\\anaconda3\\lib\\site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (68.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\loris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\loris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\loris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.13.0->lightning) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\loris\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRldKqy5-kch",
    "outputId": "5f530c16-b71a-46fa-b9cd-efd32a69e973"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5XvznjoQ1NLF",
    "outputId": "9532c721-1500-4096-f0e9-26a0a0d382f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\loris\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\loris\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: catboost in c:\\users\\loris\\anaconda3\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\loris\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\loris\\anaconda3\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Requirement already satisfied: graphviz in c:\\users\\loris\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\loris\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\loris\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\loris\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\loris\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost lightgbm catboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VXf-tJ9sGsLN"
   },
   "outputs": [],
   "source": [
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(model, dataloader, test = False):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate over batches in the dataloader\n",
    "    for batch in dataloader:\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # Convert logits to probabilities (assuming sigmoid activation for binary classification)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        # Convert probabilities to binary predictions\n",
    "        predicted_labels = (probabilities > 0.5).float()\n",
    "\n",
    "        # Append predictions and targets to lists\n",
    "        all_predictions.extend(predicted_labels.tolist())\n",
    "        all_targets.extend(targets.tolist())\n",
    "\n",
    "    # Convert predictions and targets to tensors\n",
    "    predictions_tensor = torch.tensor(all_predictions)\n",
    "    targets_tensor = torch.tensor(all_targets)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(targets_tensor, predictions_tensor)\n",
    "    \n",
    "    if test:\n",
    "        # Print classification report\n",
    "        print(classification_report(targets_tensor, predictions_tensor))\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QxnQtIRgCzyj"
   },
   "outputs": [],
   "source": [
    "class TinyModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TinyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class SmallModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SmallModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class MediumModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MediumModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "class LargeModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LargeModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 1)\n",
    "        self.activation = nn.ELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "class DropoutModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DropoutModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 1)\n",
    "        self.activation = nn.ELU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZJ1TLMb6FwGn"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XuF00Jz6ic6q"
   },
   "outputs": [],
   "source": [
    "column_names = [\"Y\"] + [str(i) for i in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "z-p_VW_fdeLV",
    "outputId": "c5b0821c-38fb-460c-afc5-098a712021b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.869293</td>\n",
       "      <td>-0.635082</td>\n",
       "      <td>0.225690</td>\n",
       "      <td>0.327470</td>\n",
       "      <td>-0.689993</td>\n",
       "      <td>0.754202</td>\n",
       "      <td>-0.248573</td>\n",
       "      <td>-1.092064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010455</td>\n",
       "      <td>-0.045767</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>1.353760</td>\n",
       "      <td>0.979563</td>\n",
       "      <td>0.978076</td>\n",
       "      <td>0.920005</td>\n",
       "      <td>0.721657</td>\n",
       "      <td>0.988751</td>\n",
       "      <td>0.876678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907542</td>\n",
       "      <td>0.329147</td>\n",
       "      <td>0.359412</td>\n",
       "      <td>1.497970</td>\n",
       "      <td>-0.313010</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>-0.557525</td>\n",
       "      <td>-1.588230</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138930</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302220</td>\n",
       "      <td>0.833048</td>\n",
       "      <td>0.985700</td>\n",
       "      <td>0.978098</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.992356</td>\n",
       "      <td>0.798343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>1.470639</td>\n",
       "      <td>-1.635975</td>\n",
       "      <td>0.453773</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>1.282322</td>\n",
       "      <td>1.381664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128848</td>\n",
       "      <td>0.900461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909753</td>\n",
       "      <td>1.108330</td>\n",
       "      <td>0.985692</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.803252</td>\n",
       "      <td>0.865924</td>\n",
       "      <td>0.780118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.344385</td>\n",
       "      <td>-0.876626</td>\n",
       "      <td>0.935913</td>\n",
       "      <td>1.992050</td>\n",
       "      <td>0.882454</td>\n",
       "      <td>1.786066</td>\n",
       "      <td>-1.646778</td>\n",
       "      <td>-0.942383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678379</td>\n",
       "      <td>-1.360356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.946652</td>\n",
       "      <td>1.028704</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.728281</td>\n",
       "      <td>0.869200</td>\n",
       "      <td>1.026736</td>\n",
       "      <td>0.957904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.105009</td>\n",
       "      <td>0.321356</td>\n",
       "      <td>1.522401</td>\n",
       "      <td>0.882808</td>\n",
       "      <td>-1.205349</td>\n",
       "      <td>0.681466</td>\n",
       "      <td>-1.070464</td>\n",
       "      <td>-0.921871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.373566</td>\n",
       "      <td>0.113041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.755856</td>\n",
       "      <td>1.361057</td>\n",
       "      <td>0.986610</td>\n",
       "      <td>0.838085</td>\n",
       "      <td>1.133295</td>\n",
       "      <td>0.872245</td>\n",
       "      <td>0.808487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.159912</td>\n",
       "      <td>1.013847</td>\n",
       "      <td>0.108615</td>\n",
       "      <td>1.495524</td>\n",
       "      <td>-0.537545</td>\n",
       "      <td>2.342396</td>\n",
       "      <td>-0.839740</td>\n",
       "      <td>1.320683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097068</td>\n",
       "      <td>1.190680</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.822136</td>\n",
       "      <td>0.766772</td>\n",
       "      <td>1.002191</td>\n",
       "      <td>1.061233</td>\n",
       "      <td>0.837004</td>\n",
       "      <td>0.860472</td>\n",
       "      <td>0.772484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.618388</td>\n",
       "      <td>-1.012982</td>\n",
       "      <td>1.110139</td>\n",
       "      <td>0.941023</td>\n",
       "      <td>-0.379199</td>\n",
       "      <td>1.004656</td>\n",
       "      <td>0.348535</td>\n",
       "      <td>-1.678593</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216995</td>\n",
       "      <td>1.049177</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.826829</td>\n",
       "      <td>0.989809</td>\n",
       "      <td>1.029104</td>\n",
       "      <td>1.199679</td>\n",
       "      <td>0.891481</td>\n",
       "      <td>0.938490</td>\n",
       "      <td>0.865269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700559</td>\n",
       "      <td>0.774251</td>\n",
       "      <td>1.520182</td>\n",
       "      <td>0.847112</td>\n",
       "      <td>0.211230</td>\n",
       "      <td>1.095531</td>\n",
       "      <td>0.052457</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>1.585235</td>\n",
       "      <td>1.713962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.845208</td>\n",
       "      <td>0.987610</td>\n",
       "      <td>0.883422</td>\n",
       "      <td>1.888438</td>\n",
       "      <td>1.153766</td>\n",
       "      <td>0.931279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.178030</td>\n",
       "      <td>0.117796</td>\n",
       "      <td>-1.276980</td>\n",
       "      <td>1.864457</td>\n",
       "      <td>-0.584370</td>\n",
       "      <td>0.998519</td>\n",
       "      <td>-1.264549</td>\n",
       "      <td>1.276333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.399515</td>\n",
       "      <td>-1.313189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838842</td>\n",
       "      <td>0.882890</td>\n",
       "      <td>1.201380</td>\n",
       "      <td>0.939216</td>\n",
       "      <td>0.339705</td>\n",
       "      <td>0.759070</td>\n",
       "      <td>0.719119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464477</td>\n",
       "      <td>-0.337047</td>\n",
       "      <td>0.229019</td>\n",
       "      <td>0.954596</td>\n",
       "      <td>-0.868466</td>\n",
       "      <td>0.430004</td>\n",
       "      <td>-0.271348</td>\n",
       "      <td>-1.252278</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.652782</td>\n",
       "      <td>-0.586254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.752535</td>\n",
       "      <td>0.740727</td>\n",
       "      <td>0.986917</td>\n",
       "      <td>0.663952</td>\n",
       "      <td>0.576084</td>\n",
       "      <td>0.541427</td>\n",
       "      <td>0.517420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Y         0         1         2         3         4         5  \\\n",
       "0         1.0  0.869293 -0.635082  0.225690  0.327470 -0.689993  0.754202   \n",
       "1         1.0  0.907542  0.329147  0.359412  1.497970 -0.313010  1.095531   \n",
       "2         1.0  0.798835  1.470639 -1.635975  0.453773  0.425629  1.104875   \n",
       "3         0.0  1.344385 -0.876626  0.935913  1.992050  0.882454  1.786066   \n",
       "4         1.0  1.105009  0.321356  1.522401  0.882808 -1.205349  0.681466   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "10999995  1.0  1.159912  1.013847  0.108615  1.495524 -0.537545  2.342396   \n",
       "10999996  1.0  0.618388 -1.012982  1.110139  0.941023 -0.379199  1.004656   \n",
       "10999997  1.0  0.700559  0.774251  1.520182  0.847112  0.211230  1.095531   \n",
       "10999998  0.0  1.178030  0.117796 -1.276980  1.864457 -0.584370  0.998519   \n",
       "10999999  0.0  0.464477 -0.337047  0.229019  0.954596 -0.868466  0.430004   \n",
       "\n",
       "                 6         7         8  ...        18        19        20  \\\n",
       "0        -0.248573 -1.092064  0.000000  ... -0.010455 -0.045767  3.101961   \n",
       "1        -0.557525 -1.588230  2.173076  ... -1.138930 -0.000819  0.000000   \n",
       "2         1.282322  1.381664  0.000000  ...  1.128848  0.900461  0.000000   \n",
       "3        -1.646778 -0.942383  0.000000  ... -0.678379 -1.360356  0.000000   \n",
       "4        -1.070464 -0.921871  0.000000  ... -0.373566  0.113041  0.000000   \n",
       "...            ...       ...       ...  ...       ...       ...       ...   \n",
       "10999995 -0.839740  1.320683  0.000000  ... -0.097068  1.190680  3.101961   \n",
       "10999996  0.348535 -1.678593  2.173076  ... -0.216995  1.049177  3.101961   \n",
       "10999997  0.052457  0.024553  2.173076  ...  1.585235  1.713962  0.000000   \n",
       "10999998 -1.264549  1.276333  0.000000  ...  1.399515 -1.313189  0.000000   \n",
       "10999999 -0.271348 -1.252278  2.173076  ... -1.652782 -0.586254  0.000000   \n",
       "\n",
       "                21        22        23        24        25        26        27  \n",
       "0         1.353760  0.979563  0.978076  0.920005  0.721657  0.988751  0.876678  \n",
       "1         0.302220  0.833048  0.985700  0.978098  0.779732  0.992356  0.798343  \n",
       "2         0.909753  1.108330  0.985692  0.951331  0.803252  0.865924  0.780118  \n",
       "3         0.946652  1.028704  0.998656  0.728281  0.869200  1.026736  0.957904  \n",
       "4         0.755856  1.361057  0.986610  0.838085  1.133295  0.872245  0.808487  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "10999995  0.822136  0.766772  1.002191  1.061233  0.837004  0.860472  0.772484  \n",
       "10999996  0.826829  0.989809  1.029104  1.199679  0.891481  0.938490  0.865269  \n",
       "10999997  0.337374  0.845208  0.987610  0.883422  1.888438  1.153766  0.931279  \n",
       "10999998  0.838842  0.882890  1.201380  0.939216  0.339705  0.759070  0.719119  \n",
       "10999999  0.752535  0.740727  0.986917  0.663952  0.576084  0.541427  0.517420  \n",
       "\n",
       "[11000000 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('HIGGS.csv.gz', header = None, names = column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "24Or0R9FbQKH",
    "outputId": "7ec7c21a-8fe7-4e70-cf85-75a1c0ba3f83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "      <td>1.100000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.299203e-01</td>\n",
       "      <td>9.914658e-01</td>\n",
       "      <td>-8.297618e-06</td>\n",
       "      <td>-1.327225e-05</td>\n",
       "      <td>9.985364e-01</td>\n",
       "      <td>2.613459e-05</td>\n",
       "      <td>9.909152e-01</td>\n",
       "      <td>-2.027520e-05</td>\n",
       "      <td>7.716199e-06</td>\n",
       "      <td>9.999687e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.756954e-06</td>\n",
       "      <td>1.744903e-05</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.034290e+00</td>\n",
       "      <td>1.024805e+00</td>\n",
       "      <td>1.050554e+00</td>\n",
       "      <td>1.009742e+00</td>\n",
       "      <td>9.729596e-01</td>\n",
       "      <td>1.033036e+00</td>\n",
       "      <td>9.598120e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.991040e-01</td>\n",
       "      <td>5.653777e-01</td>\n",
       "      <td>1.008827e+00</td>\n",
       "      <td>1.006346e+00</td>\n",
       "      <td>6.000185e-01</td>\n",
       "      <td>1.006326e+00</td>\n",
       "      <td>4.749747e-01</td>\n",
       "      <td>1.009303e+00</td>\n",
       "      <td>1.005901e+00</td>\n",
       "      <td>1.027808e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.007694e+00</td>\n",
       "      <td>1.006366e+00</td>\n",
       "      <td>1.400209e+00</td>\n",
       "      <td>6.746354e-01</td>\n",
       "      <td>3.808074e-01</td>\n",
       "      <td>1.645763e-01</td>\n",
       "      <td>3.974453e-01</td>\n",
       "      <td>5.254063e-01</td>\n",
       "      <td>3.652556e-01</td>\n",
       "      <td>3.133378e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.746966e-01</td>\n",
       "      <td>-2.434976e+00</td>\n",
       "      <td>-1.742508e+00</td>\n",
       "      <td>2.370088e-04</td>\n",
       "      <td>-1.743944e+00</td>\n",
       "      <td>1.375024e-01</td>\n",
       "      <td>-2.969725e+00</td>\n",
       "      <td>-1.741237e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.497265e+00</td>\n",
       "      <td>-1.742691e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.507046e-02</td>\n",
       "      <td>1.986757e-01</td>\n",
       "      <td>8.304866e-02</td>\n",
       "      <td>1.320062e-01</td>\n",
       "      <td>4.786215e-02</td>\n",
       "      <td>2.951122e-01</td>\n",
       "      <td>3.307214e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.907533e-01</td>\n",
       "      <td>-7.383225e-01</td>\n",
       "      <td>-8.719308e-01</td>\n",
       "      <td>5.768156e-01</td>\n",
       "      <td>-8.712081e-01</td>\n",
       "      <td>6.789927e-01</td>\n",
       "      <td>-6.872450e-01</td>\n",
       "      <td>-8.680962e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.141902e-01</td>\n",
       "      <td>-8.714789e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.906095e-01</td>\n",
       "      <td>8.462266e-01</td>\n",
       "      <td>9.857525e-01</td>\n",
       "      <td>7.675732e-01</td>\n",
       "      <td>6.738168e-01</td>\n",
       "      <td>8.193964e-01</td>\n",
       "      <td>7.703901e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>8.533714e-01</td>\n",
       "      <td>-5.415563e-05</td>\n",
       "      <td>-2.410638e-04</td>\n",
       "      <td>8.916277e-01</td>\n",
       "      <td>2.125454e-04</td>\n",
       "      <td>8.948193e-01</td>\n",
       "      <td>-2.543566e-05</td>\n",
       "      <td>5.813991e-05</td>\n",
       "      <td>1.086538e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.721330e-04</td>\n",
       "      <td>-2.642369e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.949304e-01</td>\n",
       "      <td>9.506853e-01</td>\n",
       "      <td>9.897798e-01</td>\n",
       "      <td>9.165110e-01</td>\n",
       "      <td>8.733798e-01</td>\n",
       "      <td>9.473447e-01</td>\n",
       "      <td>8.719701e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.236226e+00</td>\n",
       "      <td>7.382142e-01</td>\n",
       "      <td>8.709940e-01</td>\n",
       "      <td>1.293056e+00</td>\n",
       "      <td>8.714708e-01</td>\n",
       "      <td>1.170740e+00</td>\n",
       "      <td>6.871941e-01</td>\n",
       "      <td>8.683126e-01</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.141017e-01</td>\n",
       "      <td>8.716055e-01</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>1.024730e+00</td>\n",
       "      <td>1.083493e+00</td>\n",
       "      <td>1.020528e+00</td>\n",
       "      <td>1.142226e+00</td>\n",
       "      <td>1.138439e+00</td>\n",
       "      <td>1.140458e+00</td>\n",
       "      <td>1.059248e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.209891e+01</td>\n",
       "      <td>2.434868e+00</td>\n",
       "      <td>1.743236e+00</td>\n",
       "      <td>1.539682e+01</td>\n",
       "      <td>1.743257e+00</td>\n",
       "      <td>9.940391e+00</td>\n",
       "      <td>2.969674e+00</td>\n",
       "      <td>1.741454e+00</td>\n",
       "      <td>2.173076e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.498009e+00</td>\n",
       "      <td>1.743372e+00</td>\n",
       "      <td>3.101961e+00</td>\n",
       "      <td>4.019237e+01</td>\n",
       "      <td>2.037278e+01</td>\n",
       "      <td>7.992739e+00</td>\n",
       "      <td>1.426244e+01</td>\n",
       "      <td>1.776285e+01</td>\n",
       "      <td>1.149652e+01</td>\n",
       "      <td>8.374498e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Y             0             1             2             3  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   5.299203e-01  9.914658e-01 -8.297618e-06 -1.327225e-05  9.985364e-01   \n",
       "std    4.991040e-01  5.653777e-01  1.008827e+00  1.006346e+00  6.000185e-01   \n",
       "min    0.000000e+00  2.746966e-01 -2.434976e+00 -1.742508e+00  2.370088e-04   \n",
       "25%    0.000000e+00  5.907533e-01 -7.383225e-01 -8.719308e-01  5.768156e-01   \n",
       "50%    1.000000e+00  8.533714e-01 -5.415563e-05 -2.410638e-04  8.916277e-01   \n",
       "75%    1.000000e+00  1.236226e+00  7.382142e-01  8.709940e-01  1.293056e+00   \n",
       "max    1.000000e+00  1.209891e+01  2.434868e+00  1.743236e+00  1.539682e+01   \n",
       "\n",
       "                  4             5             6             7             8  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   2.613459e-05  9.909152e-01 -2.027520e-05  7.716199e-06  9.999687e-01   \n",
       "std    1.006326e+00  4.749747e-01  1.009303e+00  1.005901e+00  1.027808e+00   \n",
       "min   -1.743944e+00  1.375024e-01 -2.969725e+00 -1.741237e+00  0.000000e+00   \n",
       "25%   -8.712081e-01  6.789927e-01 -6.872450e-01 -8.680962e-01  0.000000e+00   \n",
       "50%    2.125454e-04  8.948193e-01 -2.543566e-05  5.813991e-05  1.086538e+00   \n",
       "75%    8.714708e-01  1.170740e+00  6.871941e-01  8.683126e-01  2.173076e+00   \n",
       "max    1.743257e+00  9.940391e+00  2.969674e+00  1.741454e+00  2.173076e+00   \n",
       "\n",
       "       ...            18            19            20            21  \\\n",
       "count  ...  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   ... -5.756954e-06  1.744903e-05  1.000000e+00  1.034290e+00   \n",
       "std    ...  1.007694e+00  1.006366e+00  1.400209e+00  6.746354e-01   \n",
       "min    ... -2.497265e+00 -1.742691e+00  0.000000e+00  7.507046e-02   \n",
       "25%    ... -7.141902e-01 -8.714789e-01  0.000000e+00  7.906095e-01   \n",
       "50%    ...  3.721330e-04 -2.642369e-04  0.000000e+00  8.949304e-01   \n",
       "75%    ...  7.141017e-01  8.716055e-01  3.101961e+00  1.024730e+00   \n",
       "max    ...  2.498009e+00  1.743372e+00  3.101961e+00  4.019237e+01   \n",
       "\n",
       "                 22            23            24            25            26  \\\n",
       "count  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07  1.100000e+07   \n",
       "mean   1.024805e+00  1.050554e+00  1.009742e+00  9.729596e-01  1.033036e+00   \n",
       "std    3.808074e-01  1.645763e-01  3.974453e-01  5.254063e-01  3.652556e-01   \n",
       "min    1.986757e-01  8.304866e-02  1.320062e-01  4.786215e-02  2.951122e-01   \n",
       "25%    8.462266e-01  9.857525e-01  7.675732e-01  6.738168e-01  8.193964e-01   \n",
       "50%    9.506853e-01  9.897798e-01  9.165110e-01  8.733798e-01  9.473447e-01   \n",
       "75%    1.083493e+00  1.020528e+00  1.142226e+00  1.138439e+00  1.140458e+00   \n",
       "max    2.037278e+01  7.992739e+00  1.426244e+01  1.776285e+01  1.149652e+01   \n",
       "\n",
       "                 27  \n",
       "count  1.100000e+07  \n",
       "mean   9.598120e-01  \n",
       "std    3.133378e-01  \n",
       "min    3.307214e-01  \n",
       "25%    7.703901e-01  \n",
       "50%    8.719701e-01  \n",
       "75%    1.059248e+00  \n",
       "max    8.374498e+00  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u2DLrflmmdmt"
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(data=df, hue=\"Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Rs65vOqP789W"
   },
   "outputs": [],
   "source": [
    "train_data = df[:-500000]\n",
    "test_data = df[-500000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrrOLdS5hlUS",
    "outputId": "a61782c7-1ed3-427c-a86b-77a3e28e4bab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500000, 500000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "g5lxsaeWh3vL"
   },
   "outputs": [],
   "source": [
    "Y_train = train_data.pop(\"Y\").values.reshape(-1, 1)\n",
    "X_train = train_data.values\n",
    "\n",
    "Y_test = test_data.pop(\"Y\").values.reshape(-1, 1)\n",
    "X_test = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t52Uby8j4l3S"
   },
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 512  # Adjust batch size according to your needs\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "obZ9Aed4Gex4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10500000, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES = X_train.shape[1]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U64EaP3IC0n0"
   },
   "source": [
    "# Defining the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "        self.accuracy = BinaryAccuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_pred, y.view(-1, 1))\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', self.accuracy(y_pred.sigmoid(), y.view(-1, 1)))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_pred = self.model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_pred, y.view(-1, 1))\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', self.accuracy(y_pred.sigmoid(), y.view(-1, 1)))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "input_size = FEATURES  # Assuming FEATURES is defined elsewhere in your code\n",
    "tiny_model = TinyModel(input_size)\n",
    "small_model = SmallModel(input_size)\n",
    "medium_model = MediumModel(input_size)\n",
    "large_model = LargeModel(input_size)\n",
    "dropout_model = DropoutModel(input_size)\n",
    "\n",
    "neuralNetsModels = {\n",
    "    \"tiny_model\": NeuralNet(tiny_model),\n",
    "    \"small_model\": NeuralNet(small_model),\n",
    "    \"medium_model\": NeuralNet(medium_model),\n",
    "    \"large_model\": NeuralNet(large_model),\n",
    "    \"dropout_model\": NeuralNet(dropout_model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "J2IReQB313tP"
   },
   "outputs": [],
   "source": [
    "dtModels = {}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "dtModels[\"RandomForest\"] = rf_model\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dtModels[\"DecisionTree\"] = dt_model\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "dtModels[\"XGBoost\"] = xgb_model\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "dtModels[\"LGBM\"] = lgb_model\n",
    "\n",
    "cat_model = CatBoostClassifier(random_state=42, verbose=False)\n",
    "dtModels[\"CatBoost\"] = cat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid[\"DecisionTree\"] = dt_param_grid\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "param_grid[\"RandomForest\"] = rf_param_grid\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [6, 10, 15],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "param_grid[\"XGBoost\"] = xgb_param_grid\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "param_grid[\"LGBM\"] = lgbm_param_grid\n",
    "\n",
    "catboost_param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'depth': [4, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "param_grid[\"CatBoost\"] = catboost_param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnppK7vD-yQr"
   },
   "source": [
    "# Numero di campioni e performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ekX6l1hWptKZ"
   },
   "outputs": [],
   "source": [
    "size_histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JKuWcl4o5HyP"
   },
   "outputs": [],
   "source": [
    "sizes = [1000, 10000, 100000, 1000000, len(train_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "wDVoRsJ9456a",
    "outputId": "df701b48-8c50-41e7-a303-7ee153b1f7dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1000</th>\n",
       "      <th colspan=\"3\" halign=\"left\">10000</th>\n",
       "      <th colspan=\"3\" halign=\"left\">100000</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1000000</th>\n",
       "      <th colspan=\"3\" halign=\"left\">10500000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny_model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium_model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>large_model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropout_model</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "size          1000                     10000                    100000    \\\n",
       "split            Train Validation Test    Train Validation Test    Train   \n",
       "RandomForest       NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "DecisionTree       NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "XGBoost            NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "LGBM               NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "CatBoost           NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "tiny_model         NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "small_model        NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "medium_model       NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "large_model        NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "dropout_model      NaN        NaN  NaN      NaN        NaN  NaN      NaN   \n",
       "\n",
       "size                          1000000                  10500000             \\\n",
       "split         Validation Test    Train Validation Test    Train Validation   \n",
       "RandomForest         NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "DecisionTree         NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "XGBoost              NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "LGBM                 NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "CatBoost             NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "tiny_model           NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "small_model          NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "medium_model         NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "large_model          NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "dropout_model        NaN  NaN      NaN        NaN  NaN      NaN        NaN   \n",
       "\n",
       "size                \n",
       "split         Test  \n",
       "RandomForest   NaN  \n",
       "DecisionTree   NaN  \n",
       "XGBoost        NaN  \n",
       "LGBM           NaN  \n",
       "CatBoost       NaN  \n",
       "tiny_model     NaN  \n",
       "small_model    NaN  \n",
       "medium_model   NaN  \n",
       "large_model    NaN  \n",
       "dropout_model  NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = pd.MultiIndex.from_product([sizes, [\"Train\", \"Validation\", \"Test\"]], names = [\"size\", \"split\"])\n",
    "results = pd.DataFrame(columns = columns, index = list(dtModels.keys()) + list(neuralNetsModels.keys()))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for RandomForest: {'max_depth': None, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.56      0.61    235493\n",
      "         1.0       0.66      0.74      0.70    264507\n",
      "\n",
      "    accuracy                           0.66    500000\n",
      "   macro avg       0.66      0.65      0.65    500000\n",
      "weighted avg       0.66      0.66      0.65    500000\n",
      "\n",
      "Best Parameters for DecisionTree: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "DecisionTree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.53      0.55    235493\n",
      "         1.0       0.60      0.63      0.62    264507\n",
      "\n",
      "    accuracy                           0.59    500000\n",
      "   macro avg       0.58      0.58      0.58    500000\n",
      "weighted avg       0.58      0.59      0.58    500000\n",
      "\n",
      "Best Parameters for XGBoost: {'learning_rate': 0.2, 'max_depth': 10, 'n_estimators': 200}\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.61      0.63    235493\n",
      "         1.0       0.67      0.71      0.69    264507\n",
      "\n",
      "    accuracy                           0.66    500000\n",
      "   macro avg       0.66      0.66      0.66    500000\n",
      "weighted avg       0.66      0.66      0.66    500000\n",
      "\n",
      "Best Parameters for LGBM: {'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 300}\n",
      "LGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.60      0.63    235493\n",
      "         1.0       0.67      0.71      0.69    264507\n",
      "\n",
      "    accuracy                           0.66    500000\n",
      "   macro avg       0.66      0.66      0.66    500000\n",
      "weighted avg       0.66      0.66      0.66    500000\n",
      "\n",
      "Best Parameters for CatBoost: {'depth': 6, 'iterations': 300, 'learning_rate': 0.01}\n",
      "CatBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.56      0.61    235493\n",
      "         1.0       0.66      0.75      0.70    264507\n",
      "\n",
      "    accuracy                           0.66    500000\n",
      "   macro avg       0.66      0.65      0.65    500000\n",
      "weighted avg       0.66      0.66      0.66    500000\n",
      "\n",
      "Best Parameters for RandomForest: {'max_depth': None, 'min_samples_leaf': 2, 'n_estimators': 300}\n",
      "RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.68      0.69    235493\n",
      "         1.0       0.72      0.73      0.72    264507\n",
      "\n",
      "    accuracy                           0.71    500000\n",
      "   macro avg       0.70      0.70      0.70    500000\n",
      "weighted avg       0.71      0.71      0.71    500000\n",
      "\n",
      "Best Parameters for DecisionTree: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "DecisionTree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.64      0.63    235493\n",
      "         1.0       0.67      0.66      0.67    264507\n",
      "\n",
      "    accuracy                           0.65    500000\n",
      "   macro avg       0.65      0.65      0.65    500000\n",
      "weighted avg       0.65      0.65      0.65    500000\n",
      "\n",
      "Best Parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 300}\n",
      "XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.69      0.69    235493\n",
      "         1.0       0.72      0.72      0.72    264507\n",
      "\n",
      "    accuracy                           0.70    500000\n",
      "   macro avg       0.70      0.70      0.70    500000\n",
      "weighted avg       0.70      0.70      0.70    500000\n",
      "\n",
      "Best Parameters for LGBM: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 300}\n",
      "LGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.70      0.69    235493\n",
      "         1.0       0.73      0.71      0.72    264507\n",
      "\n",
      "    accuracy                           0.71    500000\n",
      "   macro avg       0.71      0.71      0.71    500000\n",
      "weighted avg       0.71      0.71      0.71    500000\n",
      "\n",
      "Best Parameters for CatBoost: {'depth': 4, 'iterations': 300, 'learning_rate': 0.1}\n",
      "CatBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.69      0.69    235493\n",
      "         1.0       0.72      0.73      0.72    264507\n",
      "\n",
      "    accuracy                           0.71    500000\n",
      "   macro avg       0.71      0.71      0.71    500000\n",
      "weighted avg       0.71      0.71      0.71    500000\n",
      "\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\loris\\AppData\\Local\\Temp\\ipykernel_12608\\1118013885.py\", line 9, in <module>\n",
      "    grid_search.fit(X_training, y_training)\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 874, in fit\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1388, in _run_search\n",
      "    }\n",
      "      \n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 821, in evaluate_candidates\n",
      "    return_times=True,\n",
      "              ^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    for delayed_func, args, kwargs in iterable\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    UserWarning,\n",
      "       ^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    \"error_score must be the string 'raise' or a numeric value. \"\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 473, in fit\n",
      "    for i, t in enumerate(trees)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    for delayed_func, args, kwargs in iterable\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    UserWarning,\n",
      "       ^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 184, in _parallel_build_trees\n",
      "    curr_sample_weight *= compute_sample_weight(\"auto\", y, indices=indices)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n",
      "    \"\"\"\n",
      "        \n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 379, in fit\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\loris\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "for size in sizes:\n",
    "    X_training, X_val, y_training, y_val = train_test_split(X_train[:size], Y_train[:size], test_size=0.2, random_state=42)\n",
    "\n",
    "    for modelName in dtModels:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        y_training = y_training.ravel()\n",
    "\n",
    "        # GridSearchCV with cross-validation for each model\n",
    "        grid_search = GridSearchCV(dtModels[modelName], param_grid[modelName], cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_training, y_training)\n",
    "\n",
    "        # Print the best parameters\n",
    "        print(f\"Best Parameters for {modelName}: {grid_search.best_params_}\")\n",
    "        \n",
    "        # Using the best estimator found by the grid search\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        best_model.fit(X_training, y_training)\n",
    "    \n",
    "        predictionsTrain = best_model.predict(X_training)\n",
    "        predictionsVal = best_model.predict(X_val)\n",
    "        predictionsTest = best_model.predict(X_test)\n",
    "        \n",
    "        results[size][\"Train\"][modelName] = accuracy_score(y_training, predictionsTrain)\n",
    "        results[size][\"Validation\"][modelName] = accuracy_score(y_val, predictionsVal)\n",
    "        results[size][\"Test\"][modelName] = accuracy_score(Y_test, predictionsTest)\n",
    "        \n",
    "        print(modelName)\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        print(classification_report(Y_test, predictionsTest))\n",
    "        #print(classification_report(Y_test, binarized_predictionsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8H_ZzpBOOk-",
    "outputId": "1c291743-ccb5-4058-8881-534499b68033"
   },
   "outputs": [],
   "source": [
    "for size in sizes:\n",
    "    X_training, X_val, y_training, y_val = train_test_split(X_train[:size], Y_train[:size], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Combine X and Y datasets\n",
    "    X_training_torch = torch.tensor(X_training, dtype=torch.float32)\n",
    "    y_training_torch = torch.tensor(y_training, dtype=torch.float32)\n",
    "    X_val_torch = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_torch = torch.tensor(y_val, dtype=torch.float32)\n",
    "    \n",
    "    # Assuming you have your dataset loaded as tensors: train_x, train_y, val_x, val_y\n",
    "    train_dataset = TensorDataset(X_training_torch, y_training_torch)\n",
    "    val_dataset = TensorDataset(X_val_torch, y_val_torch)\n",
    "\n",
    "    batch_size = 512  # Adjust batch size according to your needs\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, persistent_workers=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=8, persistent_workers=True)\n",
    "\n",
    "    for modelName in neuralNetsModels:\n",
    "        print(modelName)\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Define early stopping callback\n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor='val_acc',  # Monitor validation loss\n",
    "            min_delta=0.001,     # Minimum change in validation loss to qualify as an improvement\n",
    "            patience=20,          # Number of epochs with no improvement after which training will be stopped\n",
    "            verbose=True,        # Print messages about early stopping\n",
    "            mode='max'           # Minimize validation loss\n",
    "        )\n",
    "\n",
    "        # Define ModelCheckpoint callback to save the best model\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath='checkpoints',\n",
    "            filename='modelName+str(size)',\n",
    "            monitor='val_acc',\n",
    "            mode='max',\n",
    "            save_top_k=1\n",
    "        )\n",
    "        \n",
    "        model_cloned = copy.deepcopy(neuralNetsModels[modelName])\n",
    "        \n",
    "        # Define TensorBoard logger\n",
    "        logger = TensorBoardLogger('logs', name=modelName+str(size))\n",
    "\n",
    "        # Create PyTorch Lightning trainer with TensorBoard logger\n",
    "        trainer = pl.Trainer(accelerator=\"gpu\", max_epochs=300, logger=logger, callbacks=[early_stopping_callback, checkpoint_callback])\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model_cloned, train_dataloader, val_dataloader)\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "        results[size][\"Train\"][modelName] = evaluate_binary_classification(model_cloned, train_dataloader)\n",
    "        results[size][\"Validation\"][modelName] = evaluate_binary_classification(model_cloned, val_dataloader)\n",
    "        results[size][\"Test\"][modelName] = evaluate_binary_classification(model_cloned, test_dataloader, test = True)\n",
    "\n",
    "        #print(classification_report(Y_test, binarized_predictionsTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gFYM86iZ8WKH",
    "outputId": "8c85f345-8b8f-42f4-8477-4b0f99664601"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dkEvb2x5XsjE",
    "outputId": "e33d372f-d4a7-4085-de83-3a5d9790ed15"
   },
   "outputs": [],
   "source": [
    "plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
    "plotter.plot(size_histories)\n",
    "plt.ylim([0.5, 0.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2ctIHErlM8uE",
    "outputId": "a4cb0e77-a79f-4633-9eaf-4d042624f913"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Open an embedded TensorBoard viewer\n",
    "%tensorboard --logdir {logdir}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
